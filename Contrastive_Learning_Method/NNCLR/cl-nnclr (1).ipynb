{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:39:33.715750Z","iopub.execute_input":"2025-05-28T09:39:33.716081Z","iopub.status.idle":"2025-05-28T09:39:34.060275Z","shell.execute_reply.started":"2025-05-28T09:39:33.716054Z","shell.execute_reply":"2025-05-28T09:39:34.059427Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\n\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n\nimport tensorflow as tf\nimport keras\nfrom keras import layers\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\n\n# Setting seeds for reproducibility.\nSEED = 42\nkeras.utils.set_random_seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:39:34.061584Z","iopub.execute_input":"2025-05-28T09:39:34.061967Z","iopub.status.idle":"2025-05-28T09:39:53.198664Z","shell.execute_reply.started":"2025-05-28T09:39:34.061946Z","shell.execute_reply":"2025-05-28T09:39:53.197869Z"}},"outputs":[{"name":"stderr","text":"2025-05-28 09:39:36.593996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748425176.891204      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748425177.006192      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\nshuffle_buffer = 5000\n# The below two values are taken from https://www.tensorflow.org/datasets/catalog/stl10\nlabelled_train_images = 50000\nunlabelled_images = 50000\n\ntemperature = 0.1\nqueue_size = 10000\ncontrastive_augmenter = {\n    \"brightness\": 0.5,\n    \"name\": \"contrastive_augmenter\",\n    \"scale\": (0.2, 1.0),\n}\nclassification_augmenter = {\n    \"brightness\": 0.2,\n    \"name\": \"classification_augmenter\",\n    \"scale\": (0.5, 1.0),\n}\ninput_shape = (32, 32, 3)\nwidth = 128\nnum_epochs = 10  # Use 25 for better results\nsteps_per_epoch = 25  # Use 200 for better results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:39:53.199575Z","iopub.execute_input":"2025-05-28T09:39:53.200082Z","iopub.status.idle":"2025-05-28T09:39:53.206796Z","shell.execute_reply.started":"2025-05-28T09:39:53.200058Z","shell.execute_reply":"2025-05-28T09:39:53.205564Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import tensorflow_datasets as tfds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:39:53.209093Z","iopub.execute_input":"2025-05-28T09:39:53.209470Z","iopub.status.idle":"2025-05-28T09:39:54.018630Z","shell.execute_reply.started":"2025-05-28T09:39:53.209420Z","shell.execute_reply":"2025-05-28T09:39:54.017642Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"dataset_name = \"cifar10\"\n\ndef prepare_dataset():\n    unlabeled_batch_size = unlabelled_images // steps_per_epoch\n    labeled_batch_size = labelled_train_images // steps_per_epoch\n    batch_size = unlabeled_batch_size + labeled_batch_size\n\n    # Use full train set for both labeled and unlabeled\n    full_train_dataset = tfds.load(\n        dataset_name, split=\"train\", as_supervised=True, shuffle_files=True\n    )\n\n    unlabeled_train_dataset = (\n        full_train_dataset\n        .shuffle(buffer_size=shuffle_buffer)\n        .batch(unlabeled_batch_size, drop_remainder=True)\n    )\n\n    labeled_train_dataset = (\n        full_train_dataset\n        .shuffle(buffer_size=shuffle_buffer)\n        .batch(labeled_batch_size, drop_remainder=True)\n    )\n\n    test_dataset = (\n        tfds.load(dataset_name, split=\"test\", as_supervised=True)\n        .batch(batch_size)\n        .prefetch(buffer_size=AUTOTUNE)\n    )\n\n    train_dataset = tf.data.Dataset.zip(\n        (unlabeled_train_dataset, labeled_train_dataset)\n    ).prefetch(buffer_size=AUTOTUNE)\n\n    return batch_size, train_dataset, labeled_train_dataset, test_dataset\n\nbatch_size, train_dataset, labeled_train_dataset, test_dataset = prepare_dataset()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:39:54.019480Z","iopub.execute_input":"2025-05-28T09:39:54.019760Z","iopub.status.idle":"2025-05-28T09:41:07.130215Z","shell.execute_reply.started":"2025-05-28T09:39:54.019736Z","shell.execute_reply":"2025-05-28T09:41:07.129078Z"}},"outputs":[{"name":"stdout","text":"Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/cifar10/3.0.2...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Dl Completed...: 0 url [00:00, ? url/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06a88c97bbf04bc6ac04943f62d4ef3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Dl Size...: 0 MiB [00:00, ? MiB/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c4866c34a4f446a9d3c60e60b2c1703"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extraction completed...: 0 file [00:00, ? file/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b895998149f8453e86dda95457cba260"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train examples...: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"2025-05-28 09:40:10.917993: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Shuffling /root/tensorflow_datasets/cifar10/incomplete.HBRPOI_3.0.2/cifar10-train.tfrecord*...:   0%|         …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test examples...: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Shuffling /root/tensorflow_datasets/cifar10/incomplete.HBRPOI_3.0.2/cifar10-test.tfrecord*...:   0%|          …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset cifar10 downloaded and prepared to /root/tensorflow_datasets/cifar10/3.0.2. Subsequent calls will reuse this data.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def augmenter(brightness, name, scale):\n    return keras.Sequential(\n        [\n            layers.Input(shape=input_shape),\n            layers.Rescaling(1 / 255),\n            layers.RandomFlip(\"horizontal\"),\n            keras_cv.layers.RandomCropAndResize(\n                target_size=(input_shape[0], input_shape[1]),\n                crop_area_factor=scale,\n                aspect_ratio_factor=(3 / 4, 4 / 3),\n            ),\n            keras_cv.layers.RandomBrightness(factor=brightness, value_range=(0.0, 1.0)),\n        ],\n        name=name,\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:41:07.131159Z","iopub.execute_input":"2025-05-28T09:41:07.131547Z","iopub.status.idle":"2025-05-28T09:41:07.138660Z","shell.execute_reply.started":"2025-05-28T09:41:07.131515Z","shell.execute_reply":"2025-05-28T09:41:07.137547Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def encoder():\n    return keras.Sequential(\n        [\n            layers.Input(shape=input_shape),\n            layers.Conv2D(width, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\"),\n            layers.MaxPooling2D(pool_size=2),  # Down to 16x16\n            layers.Conv2D(width, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\"),\n            layers.MaxPooling2D(pool_size=2),  # Down to 8x8\n            layers.Conv2D(width, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\"),\n            layers.GlobalAveragePooling2D(),  # Outputs shape (width,)\n            layers.Dense(width, activation=\"relu\"),\n        ],\n        name=\"encoder\",\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:41:07.139696Z","iopub.execute_input":"2025-05-28T09:41:07.139989Z","iopub.status.idle":"2025-05-28T09:41:07.158815Z","shell.execute_reply.started":"2025-05-28T09:41:07.139961Z","shell.execute_reply":"2025-05-28T09:41:07.157707Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class NNCLR(keras.Model):\n    def __init__(\n        self, temperature, queue_size,\n    ):\n        super().__init__()\n        self.probe_accuracy = keras.metrics.SparseCategoricalAccuracy()\n        self.correlation_accuracy = keras.metrics.SparseCategoricalAccuracy()\n        self.contrastive_accuracy = keras.metrics.SparseCategoricalAccuracy()\n        self.probe_loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\n        self.contrastive_augmenter = augmenter(**contrastive_augmenter)\n        self.classification_augmenter = augmenter(**classification_augmenter)\n        self.encoder = encoder()\n        self.projection_head = keras.Sequential(\n            [\n                layers.Input(shape=(width,)),\n                layers.Dense(width, activation=\"relu\"),\n                layers.Dense(width),\n            ],\n            name=\"projection_head\",\n        )\n        self.linear_probe = keras.Sequential(\n            [layers.Input(shape=(width,)), layers.Dense(10)], name=\"linear_probe\"\n        )\n        self.temperature = temperature\n\n        feature_dimensions = self.encoder.output_shape[1]\n        self.feature_queue = keras.Variable(\n            keras.utils.normalize(\n                keras.random.normal(shape=(queue_size, feature_dimensions)),\n                axis=1,\n                order=2,\n            ),\n            trainable=False,\n        )\n\n    def compile(self, contrastive_optimizer, probe_optimizer, **kwargs):\n        super().compile(**kwargs)\n        self.contrastive_optimizer = contrastive_optimizer\n        self.probe_optimizer = probe_optimizer\n\n    def nearest_neighbour(self, projections):\n        support_similarities = ops.matmul(projections, ops.transpose(self.feature_queue))\n        nn_projections = ops.take(\n            self.feature_queue, ops.argmax(support_similarities, axis=1), axis=0\n        )\n        return projections + ops.stop_gradient(nn_projections - projections)\n\n    def update_contrastive_accuracy(self, features_1, features_2):\n        features_1 = keras.utils.normalize(features_1, axis=1, order=2)\n        features_2 = keras.utils.normalize(features_2, axis=1, order=2)\n        similarities = ops.matmul(features_1, ops.transpose(features_2))\n        batch_size = ops.shape(features_1)[0]\n        contrastive_labels = ops.arange(batch_size)\n        self.contrastive_accuracy.update_state(\n            ops.concatenate([contrastive_labels, contrastive_labels], axis=0),\n            ops.concatenate([similarities, ops.transpose(similarities)], axis=0),\n        )\n\n    def update_correlation_accuracy(self, features_1, features_2):\n        features_1 = (features_1 - ops.mean(features_1, axis=0)) / ops.std(\n            features_1, axis=0\n        )\n        features_2 = (features_2 - ops.mean(features_2, axis=0)) / ops.std(\n            features_2, axis=0\n        )\n\n        batch_size = ops.shape(features_1)[0]\n        cross_correlation = (\n            ops.matmul(ops.transpose(features_1), features_2) / batch_size\n        )\n\n        feature_dim = ops.shape(features_1)[1]\n        correlation_labels = ops.arange(feature_dim)\n        self.correlation_accuracy.update_state(\n            ops.concatenate([correlation_labels, correlation_labels], axis=0),\n            ops.concatenate(\n                [cross_correlation, ops.transpose(cross_correlation)], axis=0\n            ),\n        )\n\n    def contrastive_loss(self, projections_1, projections_2):\n        projections_1 = keras.utils.normalize(projections_1, axis=1, order=2)\n        projections_2 = keras.utils.normalize(projections_2, axis=1, order=2)\n\n        similarities_1_2_1 = (\n            ops.matmul(\n                self.nearest_neighbour(projections_1), ops.transpose(projections_2)\n            )\n            / self.temperature\n        )\n        similarities_1_2_2 = (\n             ops.matmul(\n                projections_2, ops.transpose(self.nearest_neighbour(projections_1))\n            )\n            / self.temperature\n        )\n\n        similarities_2_1_1 = (\n            ops.matmul(\n                self.nearest_neighbour(projections_2), ops.transpose(projections_1)\n            )\n            / self.temperature\n        )\n        similarities_2_1_2 = (\n            ops.matmul(\n                projections_1, ops.transpose(self.nearest_neighbour(projections_2))\n            )\n            / self.temperature\n        )\n\n        batch_size = ops.shape(projections_1)[0]\n        contrastive_labels = ops.arange(batch_size)\n        loss = keras.losses.sparse_categorical_crossentropy(\n            ops.concatenate(\n                [\n                    contrastive_labels,\n                    contrastive_labels,\n                    contrastive_labels,\n                    contrastive_labels,\n                ],\n                axis=0,\n            ),\n            ops.concatenate(\n                [\n                    similarities_1_2_1,\n                    similarities_1_2_2,\n                    similarities_2_1_1,\n                    similarities_2_1_2,\n                ],\n                axis=0,\n            ),\n            from_logits=True,\n        )\n\n        new_queue = tf.concat([projections_1, self.feature_queue[:-batch_size]], axis=0)\n        self.feature_queue.assign(new_queue)\n\n        return loss\n\n    def train_step(self, data):\n        (unlabeled_images, _), (labeled_images, labels) = data\n        images = ops.concatenate((unlabeled_images, labeled_images), axis=0)\n        augmented_images_1 = self.contrastive_augmenter(images)\n        augmented_images_2 = self.contrastive_augmenter(images)\n\n        with tf.GradientTape() as tape:\n            features_1 = self.encoder(augmented_images_1)\n            features_2 = self.encoder(augmented_images_2)\n            projections_1 = self.projection_head(features_1)\n            projections_2 = self.projection_head(features_2)\n            contrastive_loss = self.contrastive_loss(projections_1, projections_2)\n        gradients = tape.gradient(\n            contrastive_loss,\n            self.encoder.trainable_weights + self.projection_head.trainable_weights,\n        )\n        self.contrastive_optimizer.apply_gradients(\n            zip(\n                gradients,\n                self.encoder.trainable_weights + self.projection_head.trainable_weights,\n            )\n        )\n        self.update_contrastive_accuracy(features_1, features_2)\n        self.update_correlation_accuracy(features_1, features_2)\n        preprocessed_images = self.classification_augmenter(labeled_images)\n\n        with tf.GradientTape() as tape:\n            features = self.encoder(preprocessed_images)\n            class_logits = self.linear_probe(features)\n            probe_loss = self.probe_loss(labels, class_logits)\n        gradients = tape.gradient(probe_loss, self.linear_probe.trainable_weights)\n        self.probe_optimizer.apply_gradients(\n            zip(gradients, self.linear_probe.trainable_weights)\n        )\n        self.probe_accuracy.update_state(labels, class_logits)\n\n        return {\n            \"c_loss\": contrastive_loss,\n            \"c_acc\": self.contrastive_accuracy.result(),\n            \"r_acc\": self.correlation_accuracy.result(),\n            \"p_loss\": probe_loss,\n            \"p_acc\": self.probe_accuracy.result(),\n        }\n\n    def test_step(self, data):\n        labeled_images, labels = data\n\n        preprocessed_images = self.classification_augmenter(\n            labeled_images, training=False\n        )\n        features = self.encoder(preprocessed_images, training=False)\n        class_logits = self.linear_probe(features, training=False)\n        probe_loss = self.probe_loss(labels, class_logits)\n\n        self.probe_accuracy.update_state(labels, class_logits)\n        return {\"p_loss\": probe_loss, \"p_acc\": self.probe_accuracy.result()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:41:07.160496Z","iopub.execute_input":"2025-05-28T09:41:07.160878Z","iopub.status.idle":"2025-05-28T09:41:07.188871Z","shell.execute_reply.started":"2025-05-28T09:41:07.160846Z","shell.execute_reply":"2025-05-28T09:41:07.187941Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import keras_cv\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:41:07.189993Z","iopub.execute_input":"2025-05-28T09:41:07.190328Z","iopub.status.idle":"2025-05-28T09:41:14.769746Z","shell.execute_reply.started":"2025-05-28T09:41:07.190300Z","shell.execute_reply":"2025-05-28T09:41:14.768867Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from keras import ops\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:41:14.772182Z","iopub.execute_input":"2025-05-28T09:41:14.772500Z","iopub.status.idle":"2025-05-28T09:41:14.777181Z","shell.execute_reply.started":"2025-05-28T09:41:14.772471Z","shell.execute_reply":"2025-05-28T09:41:14.776261Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model = NNCLR(temperature=temperature, queue_size=queue_size)\nmodel.compile(\n    contrastive_optimizer=keras.optimizers.Adam(),\n    probe_optimizer=keras.optimizers.Adam(),\n    jit_compile=False,\n)\npretrain_history = model.fit(\n    train_dataset, epochs=num_epochs, validation_data=test_dataset\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:41:14.778340Z","iopub.execute_input":"2025-05-28T09:41:14.778821Z","iopub.status.idle":"2025-05-28T12:26:19.543987Z","shell.execute_reply.started":"2025-05-28T09:41:14.778799Z","shell.execute_reply":"2025-05-28T12:26:19.541974Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1026s\u001b[0m 40s/step - c_acc: 0.0435 - c_loss: 7.7922 - p_acc: 0.1236 - p_loss: 2.2941 - r_acc: 0.1652 - val_p_acc: 0.1717 - val_p_loss: 2.2774\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m969s\u001b[0m 39s/step - c_acc: 0.0407 - c_loss: 6.9841 - p_acc: 0.1683 - p_loss: 2.2700 - r_acc: 0.3296 - val_p_acc: 0.1878 - val_p_loss: 2.2602\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m992s\u001b[0m 40s/step - c_acc: 0.0701 - c_loss: 6.3200 - p_acc: 0.1893 - p_loss: 2.2606 - r_acc: 0.5835 - val_p_acc: 0.1941 - val_p_loss: 2.2578\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1014s\u001b[0m 41s/step - c_acc: 0.1481 - c_loss: 5.5575 - p_acc: 0.1897 - p_loss: 2.2477 - r_acc: 0.7191 - val_p_acc: 0.1988 - val_p_loss: 2.2379\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m963s\u001b[0m 39s/step - c_acc: 0.1887 - c_loss: 5.3399 - p_acc: 0.1982 - p_loss: 2.2398 - r_acc: 0.7288 - val_p_acc: 0.2058 - val_p_loss: 2.2326\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1003s\u001b[0m 39s/step - c_acc: 0.2132 - c_loss: 5.0983 - p_acc: 0.2022 - p_loss: 2.2316 - r_acc: 0.7488 - val_p_acc: 0.2050 - val_p_loss: 2.2270\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m991s\u001b[0m 40s/step - c_acc: 0.2441 - c_loss: 4.8522 - p_acc: 0.2088 - p_loss: 2.2255 - r_acc: 0.7553 - val_p_acc: 0.2119 - val_p_loss: 2.2191\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m970s\u001b[0m 39s/step - c_acc: 0.2736 - c_loss: 4.7279 - p_acc: 0.2115 - p_loss: 2.2216 - r_acc: 0.7435 - val_p_acc: 0.2143 - val_p_loss: 2.2152\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1014s\u001b[0m 40s/step - c_acc: 0.2908 - c_loss: 4.5958 - p_acc: 0.2185 - p_loss: 2.2179 - r_acc: 0.7331 - val_p_acc: 0.2202 - val_p_loss: 2.2129\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Freeze the encoder weights\nencoder = model.encoder\nencoder.trainable = False\n\n# Build linear probe on top of the frozen encoder\nlinear_probe = keras.Sequential([\n    keras.Input(shape=(32, 32, 3)),  # adjust based on your image shape\n    encoder,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(10)  # 10 for CIFAR-10\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T12:26:19.547242Z","iopub.execute_input":"2025-05-28T12:26:19.547819Z","iopub.status.idle":"2025-05-28T12:26:19.896364Z","shell.execute_reply.started":"2025-05-28T12:26:19.547749Z","shell.execute_reply":"2025-05-28T12:26:19.893102Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1466366129.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Build linear probe on top of the frozen encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m linear_probe = keras.Sequential([\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# adjust based on your image shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, trainable, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrebuild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_rebuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrebuild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36m_maybe_rebuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_shape\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;31m# We can build the Sequential model if the first layer has the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36mbuild_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 \u001b[0moriginal_build_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0;31m# Record build config.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_build_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;31m# Can happen if shape inference is not implemented.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_last_axis_squeeze\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    187\u001b[0m                     \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     \u001b[0;34m\"is incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"global_average_pooling2d_1\" is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 128)"],"ename":"ValueError","evalue":"Input 0 of layer \"global_average_pooling2d_1\" is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 128)","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"linear_probe.compile(\n    optimizer=keras.optimizers.Adam(),\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[\n        'accuracy',\n        keras.metrics.Precision(name='precision'),\n        keras.metrics.Recall(name='recall'),\n        keras.metrics.AUC(name='auc'),\n        keras.metrics.AUC(name='prc', curve='PR')  # PR curve = F1-style metric\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T12:26:19.897501Z","iopub.status.idle":"2025-05-28T12:26:19.897834Z","shell.execute_reply.started":"2025-05-28T12:26:19.897689Z","shell.execute_reply":"2025-05-28T12:26:19.897702Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = linear_probe.fit(\n    labeled_train_dataset,\n    validation_data=test_dataset,\n    epochs=10\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T12:26:19.899394Z","iopub.status.idle":"2025-05-28T12:26:19.899844Z","shell.execute_reply.started":"2025-05-28T12:26:19.899635Z","shell.execute_reply":"2025-05-28T12:26:19.899655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nimport numpy as np\n\n# Predict on test set\ny_true = []\ny_pred = []\n\nfor images, labels in test_dataset:\n    preds = linear_probe.predict(images)\n    y_true.extend(labels.numpy())\n    y_pred.extend(np.argmax(preds, axis=1))\n\nf1 = f1_score(y_true, y_pred, average='macro')\nprint(f\"F1 Score: {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T12:26:19.902230Z","iopub.status.idle":"2025-05-28T12:26:19.903144Z","shell.execute_reply.started":"2025-05-28T12:26:19.902824Z","shell.execute_reply":"2025-05-28T12:26:19.902848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.legend()\nplt.title(\"Loss over epochs\")\nplt.show()\n\nplt.plot(history.history['accuracy'], label='Train Acc')\nplt.plot(history.history['val_accuracy'], label='Val Acc')\nplt.legend()\nplt.title(\"Accuracy over epochs\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T12:26:19.905833Z","iopub.status.idle":"2025-05-28T12:26:19.906466Z","shell.execute_reply.started":"2025-05-28T12:26:19.906285Z","shell.execute_reply":"2025-05-28T12:26:19.906307Z"}},"outputs":[],"execution_count":null}]}